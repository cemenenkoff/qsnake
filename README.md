# Snake and Deep Q Reinforcement Learning
### Overview
- **Reinforcement learning** is a style of machine learning that relies on past experience to develop a policy on what do to next.
- **Deep neural networks** are used in machine learning to set up decision pathways that maximize reward (i.e. minimize loss or error).
- **Q-learning** is a subclass of reinforcement learning that is *model-free*, meaning that it does not require a model of the environment in which it operates. Given a reward structure (e.g. 10 points for eating an apple, but -100 for eating a body chunk), Q-learning can handle problems with inherent randomness (e.g. the apple respawning).

In this exploration, a **policy** is a strategy to win the game of snake. Q-learning finds an *optimal* policy in the sense of maximizing the expected value of the total reward over any and all steps in the game, starting from an initial state.

The agent's policy begins as *"move randomly and hope for the best"* but changes as it completes more games in efforts to find an *optimal action-selection policy* (where the possible actions are up, down, left, and right). The more times the agent is able to play, the more its random movements are replaced by the continually developing policy.
____
This project contains the following files:
____
**config.json**

This configuration file defines how the script should run. All of the keys in
the example below are required along with their example data types.

```yaml
{
    "project_root_dir": ".",
    "human": false,
    "name": "nick",
    "save_for_gif": false,
    "make_gif": false,
    "params":{
        "epsilon": 1,
        "gamma": 0.95,
        "batch_size": 256,
        "epsilon_min": 0.001,
        "epsilon_decay": 0.98,
        "learning_rate": 0.00025,
        "layer_sizes": [128, 128, 128],
        "num_episodes": 15,
        "state_definition_type": "default"
    }
}
```
____
**explore.py**

Running `python explore.py -c config.json` gets things going.
____
**requirements.txt**

After cloning this repository, run `pip install -r requirements.txt` to set up your environment. This project runs on **Python 3.9.7**, and some of the main modules utilized in this demo are **tensorflow**, **keras**, **turtle**, and **gym**.
____
**environment.py**

This is the environment that represents the snake game.
____
**agent.py**

This script trains an agent to play snake via a deep Q-learning network.
____
**plotting.py**

This is a supporting script that graphs some statistics about how the network was trained and the performance of the agent.
____

## I recommend setting up this project in a **virtual environment**.

#### If you are new to python programming, I'd reccommend the following steps:

1. Download and install VS Code.

2. Install Python 3.9.7 (add it to PATH if you have no other Python versions installed).

3. Install Git bash.

4. OPTIONAL: If you want to utilize the `"save_for_gif"` and `"make_gif"` options in the main config, install Ghostscript and note the path of the binary. You will need to change a line in the preamble of **gif_creator.py**.

5. Run `pip install virtualenv`.

6. Run `python -m virtualenv <myenvname> --python=python3.9.7`.

7. Navigate to the main project folder that contains `<myenvname>` via `cd <projdir>`.

8. On Windows, run `./<myenvname>/Scripts/activate` to activate the virtual environment.

9.  On Linux or Mac (or if prompted), run `source <myenvname>/bin/activate` to do the same thing.

10. Once your virtual environment is activated, close and restart your VS Code terminal.

11. You should see a `(<myenvname>)` string next to the  terminal input when the environment is active.

12. Press `Ctrl+Shift+P` (on Windows) to open VS Code's command palette.

13. From the dropdown menu, click `Python: Select Interpreter`.

14. Select `Python 3.9.7 64-bit ('<myenvname>':venv)` (it may already be selected automatically).

15. Run `pip list` to see a list of installed packages. It should only have two modules.

16. Run `pip install -r requirements.txt` to install all dependencies on your activated virtual environment.

17. Once everything is installed, run `python environment.py` to test if you can play the game manually.

18. Next, run `python agent.py` to see if the agent is able to play the game.

19. Let the agent run to the end and check that **plotting.py** is able to produce a graph.

20. Have fun experimenting with the code.

21. If you are brand new to reinforcement learning, I would recommend reading through **environment.py** before **agent.py**.

____

## To do:

- ~~Allow for several user-definable agents via **config.json** files.~~

- ~~Clean up **plotting.py** and add the ability to save figures locally.~~

- ~~Add hyperparameter settings to the learning curve figure generated by **plotting.py**.~~

- Expand **README.md** to include a high-level overview of how the network is trained via a **Bellman equation**.

- **Allow for models to be saved.**

- **Allow previously trained models to play with saved settings.**

- **Allow previously trained models to play and resume training.**

- ~~Expand **plotting.py** to store a hyperparameter configuration's collection of training episodes as a gif.~~
